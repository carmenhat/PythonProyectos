import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import os
import json
from tqdm import tqdm
from urllib.parse import quote

# Constantes
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.9"
}

# Lista expandida de paÃ­ses relevantes (con emojis de banderas)
COUNTRY_EMOJIS = {
    "Spain": "ğŸ‡ªğŸ‡¸ Spain",
    "France": "ğŸ‡«ğŸ‡· France",
    "USA": "ğŸ‡ºğŸ‡¸ USA",
    "United States": "ğŸ‡ºğŸ‡¸ USA",
    "Italy": "ğŸ‡®ğŸ‡¹ Italy",
    "Japan": "ğŸ‡¯ğŸ‡µ Japan",
    "South Korea": "ğŸ‡°ğŸ‡· South Korea", 
    "United Kingdom": "ğŸ‡¬ğŸ‡§ United Kingdom",
    "UK": "ğŸ‡¬ğŸ‡§ United Kingdom",
    "Mexico": "ğŸ‡²ğŸ‡½ Mexico",
    "Canada": "ğŸ‡¨ğŸ‡¦ Canada",
    "Denmark": "ğŸ‡©ğŸ‡° Denmark",
    "Switzerland": "ğŸ‡¨ğŸ‡­ Switzerland",
    "Turkey": "ğŸ‡¹ğŸ‡· Turkey",
    "Iran": "ğŸ‡®ğŸ‡· Iran",
    "Germany": "ğŸ‡©ğŸ‡ª Germany",
    "Austria": "ğŸ‡¦ğŸ‡¹ Austria",
    "Belgium": "ğŸ‡§ğŸ‡ª Belgium",
    "Brazil": "ğŸ‡§ğŸ‡· Brazil",
    "China": "ğŸ‡¨ğŸ‡³ China",
    "Russia": "ğŸ‡·ğŸ‡º Russia",
    "Sweden": "ğŸ‡¸ğŸ‡ª Sweden"
}

# Nombre del archivo de checkpoint para guardar progreso
CHECKPOINT_FILE = "datos_generados/country_enrichment_checkpoint.json"

def scrape_imdb_for_countries(imdb_id):
    """Extrae informaciÃ³n de los paÃ­ses de una pelÃ­cula en IMDb."""
    if not imdb_id:
        return []
        
    url = f"https://www.imdb.com/title/{imdb_id}/"
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        
        countries = []
        
        # MÃ©todo 1: Buscar en los metadatos principales
        metadata_blocks = soup.select(".ipc-metadata-list")
        for block in metadata_blocks:
            header = block.select_one(".ipc-metadata-list-item__label")
            if header and ("Countries of origin" in header.text or "Country of origin" in header.text or "PaÃ­s de origen" in header.text):
                country_elements = block.select(".ipc-metadata-list-item__list-content-item")
                for element in country_elements:
                    countries.append(element.text.strip())
                break
        
        # MÃ©todo 2: Buscar en la informaciÃ³n tÃ©cnica si estÃ¡ disponible
        if not countries:
            details_page = f"https://www.imdb.com/title/{imdb_id}/technical/"
            try:
                details_response = requests.get(details_page, headers=HEADERS, timeout=10)
                details_response.raise_for_status()
                details_soup = BeautifulSoup(details_response.text, "html.parser")
                
                for item in details_soup.select(".technical-list li"):
                    label = item.select_one("h4")
                    if label and "Country" in label.text:
                        value = item.select_one("div")
                        if value:
                            for country in value.text.split(","):
                                countries.append(country.strip())
            except Exception as e:
                print(f"Error obteniendo detalles tÃ©cnicos para {imdb_id}: {e}")
        
        # MÃ©todo 3: Buscar en la secciÃ³n "Details" de la pÃ¡gina principal
        if not countries:
            details_section = soup.select_one("[data-testid='title-details-section']")
            if details_section:
                country_item = details_section.find(lambda tag: tag.name == "li" and "Country" in tag.text)
                if country_item:
                    country_links = country_item.select("a")
                    for link in country_links:
                        countries.append(link.text.strip())
        
        return countries
        
    except Exception as e:
        print(f"Error obteniendo paÃ­ses para {imdb_id}: {e}")
        return []

def save_checkpoint(processed_ids):
    """Guarda un checkpoint de los IDs ya procesados."""
    directory = os.path.dirname(CHECKPOINT_FILE)
    if not os.path.exists(directory):
        os.makedirs(directory)
        
    with open(CHECKPOINT_FILE, 'w') as f:
        json.dump({"processed_ids": list(processed_ids)}, f)
    
    print(f"âœ… Checkpoint guardado: {len(processed_ids)} pelÃ­culas procesadas")

def load_checkpoint():
    """Carga el checkpoint de IDs procesados."""
    if os.path.exists(CHECKPOINT_FILE):
        with open(CHECKPOINT_FILE, 'r') as f:
            data = json.load(f)
            return set(data.get("processed_ids", []))
    return set()

def enrich_countries(input_file, output_file):
    """
    Enriquece los datos de paÃ­ses de las pelÃ­culas utilizando IMDb.
    
    Args:
        input_file (str): Ruta al archivo Excel con los datos de pelÃ­culas
        output_file (str): Ruta donde guardar el archivo Excel enriquecido
    """
    print(f"ğŸ“Š Cargando archivo '{input_file}'...")
    df = pd.read_excel(input_file)
    
    # Crear columna country_expanded si no existe
    if 'country_expanded' not in df.columns:
        df['country_expanded'] = df['country_esp_fra_usa'].copy()
    
    # Cargar checkpoint de IDs ya procesados
    processed_ids = load_checkpoint()
    
    # Contar pelÃ­culas que necesitan ser procesadas
    need_processing = df[
        (df['imdb_id'].notna()) & 
        (df['imdb_id'] != "") & 
        (~df['imdb_id'].isin(processed_ids)) &
        (
            (df['country_expanded'].isna()) | 
            (df['country_expanded'] == "") |
            # TambiÃ©n procesamos pelÃ­culas con solo algunos paÃ­ses (para aÃ±adir mÃ¡s si es posible)
            (df['country_expanded'].str.count(',') < 1)
        )
    ]
    
    total_to_process = len(need_processing)
    print(f"ğŸ¬ Total de pelÃ­culas a procesar: {total_to_process}")
    print(f"ğŸ“Œ PelÃ­culas ya procesadas anteriormente: {len(processed_ids)}")
    
    # Preguntar al usuario si quiere continuar
    if total_to_process > 0:
        # Procesar cada pelÃ­cula con ID de IMDb pero sin datos completos de paÃ­s
        progress_bar = tqdm(total=total_to_process, desc="Procesando pelÃ­culas")
        
        save_interval = max(1, min(50, total_to_process // 10))  # Guardar cada 10% del progreso
        count = 0
        
        for i, row in need_processing.iterrows():
            imdb_id = row['imdb_id']
            
            # Obtener paÃ­ses de IMDb
            countries = scrape_imdb_for_countries(imdb_id)
            
            if countries:
                # Convertir a formato con emoji
                countries_with_emoji = []
                for country in countries:
                    for target, emoji_name in COUNTRY_EMOJIS.items():
                        if target in country:
                            countries_with_emoji.append(emoji_name)
                            break
                
                # Si encontramos paÃ­ses con emoji, actualizar
                if countries_with_emoji:
                    # Si ya habÃ­a datos, combinar
                    if pd.notna(df.at[i, 'country_expanded']) and df.at[i, 'country_expanded'] != "":
                        existing = df.at[i, 'country_expanded'].split(', ')
                        combined = list(set(existing + countries_with_emoji))
                        df.at[i, 'country_expanded'] = ", ".join(combined)
                    else:
                        df.at[i, 'country_expanded'] = ", ".join(countries_with_emoji)
                    
                    # Mostrar resultados
                    tqdm.write(f"âœ… {row['title']} ({row['year']}): {', '.join(countries)}")
                    tqdm.write(f"   â†’ Con emoji: {df.at[i, 'country_expanded']}")
                else:
                    tqdm.write(f"âš ï¸ {row['title']}: No se encontraron coincidencias de paÃ­ses en la lista de paÃ­ses objetivo")
            else:
                tqdm.write(f"âŒ {row['title']}: No se encontraron datos de paÃ­ses")
            
            # Marcar como procesado
            processed_ids.add(imdb_id)
            
            # Actualizar la barra de progreso
            progress_bar.update(1)
            count += 1
            
            # Guardar checkpoint y datos intermedios
            if count % save_interval == 0:
                save_checkpoint(processed_ids)
                df.to_excel(output_file, index=False)
                tqdm.write(f"ğŸ’¾ Guardando progreso intermedio ({count}/{total_to_process})")
            
            # Pausa para no sobrecargar el servidor
            time.sleep(1)
        
        progress_bar.close()
    
    # Guardar resultados finales
    save_checkpoint(processed_ids)
    df.to_excel(output_file, index=False)
    print(f"\nâœ… Proceso completado. Datos guardados en '{output_file}'")
    
    # Mostrar estadÃ­sticas finales
    total_with_countries = df['country_expanded'].notna().sum()
    print(f"\nğŸ“Š EstadÃ­sticas finales:")
    print(f"   - Total de pelÃ­culas: {len(df)}")
    print(f"   - PelÃ­culas con datos de paÃ­s: {total_with_countries} ({total_with_countries/len(df)*100:.1f}%)")
    
    # Contar pelÃ­culas por paÃ­s
    if total_with_countries > 0:
        country_counts = {}
        for country_list in df['country_expanded'].dropna():
            for country in country_list.split(', '):
                country_counts[country] = country_counts.get(country, 0) + 1
        
        print("\nğŸŒ PelÃ­culas por paÃ­s:")
        for country, count in sorted(country_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"   {country}: {count}")

def main():
    """FunciÃ³n principal para enriquecer los datos de paÃ­ses."""
    try:
        # Obtener la ruta del directorio donde estÃ¡ el script
        script_dir = os.path.dirname(os.path.abspath(__file__))

        # Definir rutas relativas basadas en el directorio del script
        input_file = os.path.join(script_dir, "datos_generados/cannes_con_imdb.xlsx")
        output_file = os.path.join(script_dir, "datos_generados/cannes_final.xlsx")

        # Enriquecer los datos
        enrich_countries(input_file, output_file)
        
    except Exception as e:
        print(f"\nâŒ Error en el procesamiento: {e}")

if __name__ == "__main__":
    main()
